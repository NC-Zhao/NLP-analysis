{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bfee833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5708160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train= pd.read_csv('data_reviews/x_train.csv')\n",
    "y_train= pd.read_csv('data_reviews/y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33fd392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4db5aee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \\.?()0123456789:;[]\\x85\\x96\\x97\"#$%&()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0de1ac97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04047b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website_name</th>\n",
       "      <th>text</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Oh and I forgot to also mention the weird colo...</td>\n",
       "      <td>oh and i forgot to also mention the weird colo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon</td>\n",
       "      <td>THAT one didn't work either.</td>\n",
       "      <td>that one did not work either</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Waste of 13 bucks.</td>\n",
       "      <td>waste of bucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Product is useless, since it does not have eno...</td>\n",
       "      <td>product is useless since it does not have enou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazon</td>\n",
       "      <td>None of the three sizes they sent with the hea...</td>\n",
       "      <td>none of the three sizes they sent with the hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>yelp</td>\n",
       "      <td>The sweet potato fries were very good and seas...</td>\n",
       "      <td>the sweet potato fries were very good and seas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>yelp</td>\n",
       "      <td>I could eat their bruschetta all day it is dev...</td>\n",
       "      <td>i could eat their bruschetta all day it is devine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>yelp</td>\n",
       "      <td>Ambience is perfect.</td>\n",
       "      <td>ambience is perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>yelp</td>\n",
       "      <td>We ordered the duck rare and it was pink and t...</td>\n",
       "      <td>we ordered the duck rare and it was pink and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>yelp</td>\n",
       "      <td>Service was good and the company was better!</td>\n",
       "      <td>service was good and the company was better</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     website_name                                               text  \\\n",
       "0          amazon  Oh and I forgot to also mention the weird colo...   \n",
       "1          amazon                       THAT one didn't work either.   \n",
       "2          amazon                                 Waste of 13 bucks.   \n",
       "3          amazon  Product is useless, since it does not have eno...   \n",
       "4          amazon  None of the three sizes they sent with the hea...   \n",
       "...           ...                                                ...   \n",
       "2395         yelp  The sweet potato fries were very good and seas...   \n",
       "2396         yelp  I could eat their bruschetta all day it is dev...   \n",
       "2397         yelp                               Ambience is perfect.   \n",
       "2398         yelp  We ordered the duck rare and it was pink and t...   \n",
       "2399         yelp       Service was good and the company was better!   \n",
       "\n",
       "                                         text_processed  \n",
       "0     oh and i forgot to also mention the weird colo...  \n",
       "1                          that one did not work either  \n",
       "2                                        waste of bucks  \n",
       "3     product is useless since it does not have enou...  \n",
       "4     none of the three sizes they sent with the hea...  \n",
       "...                                                 ...  \n",
       "2395  the sweet potato fries were very good and seas...  \n",
       "2396  i could eat their bruschetta all day it is devine  \n",
       "2397                                ambience is perfect  \n",
       "2398  we ordered the duck rare and it was pink and t...  \n",
       "2399        service was good and the company was better  \n",
       "\n",
       "[2400 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#lower case\n",
    "x_train['text_processed'] = x_train['text'].map(lambda x: x.lower())\n",
    "\n",
    "# contractions\n",
    "def contractions(s):\n",
    "    s = re.sub(r\"won’t\", \"will not\",s)\n",
    "    s = re.sub(r\"would’t\",\"would not\",s)\n",
    "    s = re.sub(r\"could’t\", \"could not\",s)\n",
    "    s = re.sub(r\"\\'d\", \" would\",s)\n",
    "    s = re.sub(r\"can\\'t\", \"can not\",s)\n",
    "    s = re.sub(r\"n\\'t\", \" not\", s)\n",
    "    s = re.sub(r\"\\'re\", \" are\", s)\n",
    "    s = re.sub(r\"\\'s\", \" is\", s)\n",
    "    s = re.sub(r\"\\'ll\", \" will\", s)\n",
    "    s = re.sub(r\"\\'t\", \" not\", s)\n",
    "    s = re.sub(r\"\\'ve\", \" have\", s)\n",
    "    s = re.sub(r\"\\'m\", \" am\", s)\n",
    "    return s\n",
    "x_train['text_processed'] = x_train['text_processed'].map(lambda x: contractions(x))\n",
    "\n",
    "x_train['text_processed'] = x_train['text_processed'].map(lambda x: re.sub('[.!,\\.?()0123456789:;\\x85\\x96\\x97\"#$%&()\\[\\]*+-/\\']', '', x))\n",
    "\n",
    "# remove non-alpha words\n",
    "import nltk\n",
    "x_train['text_processed'] = x_train['text_processed'].apply(lambda x: \" \".join([re.sub('[^A-Za-z]+','',x) for x in nltk.word_tokenize(x)]))\n",
    "\n",
    "# remove extra spaces\n",
    "x_train['text_processed'] = x_train['text_processed'].apply(lambda x: re.sub(' +',' ', x))\n",
    "\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c08d844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents = x_train['text_processed'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "669bd243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website_name</th>\n",
       "      <th>text</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Oh and I forgot to also mention the weird colo...</td>\n",
       "      <td>oh and i forgot to also mention the weird colo...</td>\n",
       "      <td>oh forgot also mention weird color effect phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon</td>\n",
       "      <td>THAT one didn't work either.</td>\n",
       "      <td>that one did not work either</td>\n",
       "      <td>one work either</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Waste of 13 bucks.</td>\n",
       "      <td>waste of bucks</td>\n",
       "      <td>waste bucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Product is useless, since it does not have eno...</td>\n",
       "      <td>product is useless since it does not have enou...</td>\n",
       "      <td>product useless since enough charging current ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazon</td>\n",
       "      <td>None of the three sizes they sent with the hea...</td>\n",
       "      <td>none of the three sizes they sent with the hea...</td>\n",
       "      <td>none three sizes sent headset would stay ears</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>yelp</td>\n",
       "      <td>The sweet potato fries were very good and seas...</td>\n",
       "      <td>the sweet potato fries were very good and seas...</td>\n",
       "      <td>sweet potato fries good seasoned well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>yelp</td>\n",
       "      <td>I could eat their bruschetta all day it is dev...</td>\n",
       "      <td>i could eat their bruschetta all day it is devine</td>\n",
       "      <td>could eat bruschetta day devine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>yelp</td>\n",
       "      <td>Ambience is perfect.</td>\n",
       "      <td>ambience is perfect</td>\n",
       "      <td>ambience perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>yelp</td>\n",
       "      <td>We ordered the duck rare and it was pink and t...</td>\n",
       "      <td>we ordered the duck rare and it was pink and t...</td>\n",
       "      <td>ordered duck rare pink tender inside nice char...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>yelp</td>\n",
       "      <td>Service was good and the company was better!</td>\n",
       "      <td>service was good and the company was better</td>\n",
       "      <td>service good company better</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     website_name                                               text  \\\n",
       "0          amazon  Oh and I forgot to also mention the weird colo...   \n",
       "1          amazon                       THAT one didn't work either.   \n",
       "2          amazon                                 Waste of 13 bucks.   \n",
       "3          amazon  Product is useless, since it does not have eno...   \n",
       "4          amazon  None of the three sizes they sent with the hea...   \n",
       "...           ...                                                ...   \n",
       "2395         yelp  The sweet potato fries were very good and seas...   \n",
       "2396         yelp  I could eat their bruschetta all day it is dev...   \n",
       "2397         yelp                               Ambience is perfect.   \n",
       "2398         yelp  We ordered the duck rare and it was pink and t...   \n",
       "2399         yelp       Service was good and the company was better!   \n",
       "\n",
       "                                         text_processed  \\\n",
       "0     oh and i forgot to also mention the weird colo...   \n",
       "1                          that one did not work either   \n",
       "2                                        waste of bucks   \n",
       "3     product is useless since it does not have enou...   \n",
       "4     none of the three sizes they sent with the hea...   \n",
       "...                                                 ...   \n",
       "2395  the sweet potato fries were very good and seas...   \n",
       "2396  i could eat their bruschetta all day it is devine   \n",
       "2397                                ambience is perfect   \n",
       "2398  we ordered the duck rare and it was pink and t...   \n",
       "2399        service was good and the company was better   \n",
       "\n",
       "                                                      1  \n",
       "0       oh forgot also mention weird color effect phone  \n",
       "1                                       one work either  \n",
       "2                                           waste bucks  \n",
       "3     product useless since enough charging current ...  \n",
       "4         none three sizes sent headset would stay ears  \n",
       "...                                                 ...  \n",
       "2395              sweet potato fries good seasoned well  \n",
       "2396                    could eat bruschetta day devine  \n",
       "2397                                   ambience perfect  \n",
       "2398  ordered duck rare pink tender inside nice char...  \n",
       "2399                        service good company better  \n",
       "\n",
       "[2400 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "x_train['1'] = x_train['text_processed'].apply(lambda x: \" \".join([x for x in x.split() if x not in stop]))\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "940bc168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "059d516b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website_name</th>\n",
       "      <th>text</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Oh and I forgot to also mention the weird colo...</td>\n",
       "      <td>oh and i forgot to also mention the weird colo...</td>\n",
       "      <td>oh forgot also mention weird color effect phone</td>\n",
       "      <td>oh and i forgot to also mention the weird colo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon</td>\n",
       "      <td>THAT one didn't work either.</td>\n",
       "      <td>that one did not work either</td>\n",
       "      <td>one work either</td>\n",
       "      <td>that one did not work either</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Waste of 13 bucks.</td>\n",
       "      <td>waste of bucks</td>\n",
       "      <td>waste buck</td>\n",
       "      <td>waste of buck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Product is useless, since it does not have eno...</td>\n",
       "      <td>product is useless since it does not have enou...</td>\n",
       "      <td>product useless since enough charging current ...</td>\n",
       "      <td>product is useless since it doe not have enoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazon</td>\n",
       "      <td>None of the three sizes they sent with the hea...</td>\n",
       "      <td>none of the three sizes they sent with the hea...</td>\n",
       "      <td>none three size sent headset would stay ear</td>\n",
       "      <td>none of the three size they sent with the head...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>yelp</td>\n",
       "      <td>The sweet potato fries were very good and seas...</td>\n",
       "      <td>the sweet potato fries were very good and seas...</td>\n",
       "      <td>sweet potato fry good seasoned well</td>\n",
       "      <td>the sweet potato fry were very good and season...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>yelp</td>\n",
       "      <td>I could eat their bruschetta all day it is dev...</td>\n",
       "      <td>i could eat their bruschetta all day it is devine</td>\n",
       "      <td>could eat bruschetta day devine</td>\n",
       "      <td>i could eat their bruschetta all day it is devine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>yelp</td>\n",
       "      <td>Ambience is perfect.</td>\n",
       "      <td>ambience is perfect</td>\n",
       "      <td>ambience perfect</td>\n",
       "      <td>ambience is perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>yelp</td>\n",
       "      <td>We ordered the duck rare and it was pink and t...</td>\n",
       "      <td>we ordered the duck rare and it was pink and t...</td>\n",
       "      <td>ordered duck rare pink tender inside nice char...</td>\n",
       "      <td>we ordered the duck rare and it wa pink and te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>yelp</td>\n",
       "      <td>Service was good and the company was better!</td>\n",
       "      <td>service was good and the company was better</td>\n",
       "      <td>service good company better</td>\n",
       "      <td>service wa good and the company wa better</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     website_name                                               text  \\\n",
       "0          amazon  Oh and I forgot to also mention the weird colo...   \n",
       "1          amazon                       THAT one didn't work either.   \n",
       "2          amazon                                 Waste of 13 bucks.   \n",
       "3          amazon  Product is useless, since it does not have eno...   \n",
       "4          amazon  None of the three sizes they sent with the hea...   \n",
       "...           ...                                                ...   \n",
       "2395         yelp  The sweet potato fries were very good and seas...   \n",
       "2396         yelp  I could eat their bruschetta all day it is dev...   \n",
       "2397         yelp                               Ambience is perfect.   \n",
       "2398         yelp  We ordered the duck rare and it was pink and t...   \n",
       "2399         yelp       Service was good and the company was better!   \n",
       "\n",
       "                                         text_processed  \\\n",
       "0     oh and i forgot to also mention the weird colo...   \n",
       "1                          that one did not work either   \n",
       "2                                        waste of bucks   \n",
       "3     product is useless since it does not have enou...   \n",
       "4     none of the three sizes they sent with the hea...   \n",
       "...                                                 ...   \n",
       "2395  the sweet potato fries were very good and seas...   \n",
       "2396  i could eat their bruschetta all day it is devine   \n",
       "2397                                ambience is perfect   \n",
       "2398  we ordered the duck rare and it was pink and t...   \n",
       "2399        service was good and the company was better   \n",
       "\n",
       "                                                      1  \\\n",
       "0       oh forgot also mention weird color effect phone   \n",
       "1                                       one work either   \n",
       "2                                            waste buck   \n",
       "3     product useless since enough charging current ...   \n",
       "4           none three size sent headset would stay ear   \n",
       "...                                                 ...   \n",
       "2395                sweet potato fry good seasoned well   \n",
       "2396                    could eat bruschetta day devine   \n",
       "2397                                   ambience perfect   \n",
       "2398  ordered duck rare pink tender inside nice char...   \n",
       "2399                        service good company better   \n",
       "\n",
       "                                                      2  \n",
       "0     oh and i forgot to also mention the weird colo...  \n",
       "1                          that one did not work either  \n",
       "2                                         waste of buck  \n",
       "3     product is useless since it doe not have enoug...  \n",
       "4     none of the three size they sent with the head...  \n",
       "...                                                 ...  \n",
       "2395  the sweet potato fry were very good and season...  \n",
       "2396  i could eat their bruschetta all day it is devine  \n",
       "2397                                ambience is perfect  \n",
       "2398  we ordered the duck rare and it wa pink and te...  \n",
       "2399          service wa good and the company wa better  \n",
       "\n",
       "[2400 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "x_train['1'] = x_train['1'].apply(lambda x: \" \".join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(x)]))\n",
    "x_train['2'] = x_train['text_processed'].apply(lambda x: \" \".join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(x)]))\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a99bcde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.26132774353027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhaohui Zhang\\.conda\\envs\\ml135_env_sp21\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "# countvectorize\n",
    "\n",
    "from time import time as time\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {'mlp__hidden_layer_sizes':[(100,), (50,), (25,), (200,), (50,50), (100,100)], \n",
    "              'mlp__activation': ['identity', 'logistic', 'tanh', 'relu'], \n",
    "              'mlp__solver': ['lbfgs', 'sgd', 'adam'],\n",
    "              'mlp__alpha': np.logspace(-4, 2, 100),\n",
    "              'mlp__max_iter': [100, 200, 50]          \n",
    "             }\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer()),\n",
    "        ('mlp', MLPClassifier())\n",
    "    ]\n",
    ")\n",
    "grid = RandomizedSearchCV(pipeline, param_grid, n_iter = 2, return_train_score = False, n_jobs = -1)\n",
    "\n",
    "a = time()\n",
    "grid.fit(x_train['text_processed'], y_train.values.reshape(-1))\n",
    "# print(grid.cv_results_)\n",
    "# print(grid.best_params_)\n",
    "# print(grid.best_score_)\n",
    "\n",
    "print(time() - a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ec7cff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([11.00231557, 26.0445601 ]), 'std_fit_time': array([0.31831519, 5.63915045]), 'mean_score_time': array([0.01874518, 0.02499185]), 'std_score_time': array([0.0062505 , 0.00765803]), 'param_mlp__solver': masked_array(data=['lbfgs', 'adam'],\n",
      "             mask=[False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_mlp__max_iter': masked_array(data=[100, 50],\n",
      "             mask=[False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_mlp__hidden_layer_sizes': masked_array(data=[(50, 50), (100, 100)],\n",
      "             mask=[False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_mlp__alpha': masked_array(data=[2.310129700083158, 37.649358067924716],\n",
      "             mask=[False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_mlp__activation': masked_array(data=['identity', 'relu'],\n",
      "             mask=[False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'mlp__solver': 'lbfgs', 'mlp__max_iter': 100, 'mlp__hidden_layer_sizes': (50, 50), 'mlp__alpha': 2.310129700083158, 'mlp__activation': 'identity'}, {'mlp__solver': 'adam', 'mlp__max_iter': 50, 'mlp__hidden_layer_sizes': (100, 100), 'mlp__alpha': 37.649358067924716, 'mlp__activation': 'relu'}], 'split0_test_score': array([0.8, 0.5]), 'split1_test_score': array([0.80625, 0.5    ]), 'split2_test_score': array([0.74166667, 0.5       ]), 'split3_test_score': array([0.75416667, 0.5       ]), 'split4_test_score': array([0.82708333, 0.5       ]), 'mean_test_score': array([0.78583333, 0.5       ]), 'std_test_score': array([0.03247328, 0.        ]), 'rank_test_score': array([1, 2])}\n"
     ]
    }
   ],
   "source": [
    "print(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85550a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # countvectorize\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param_grid = {'vect__max_df':[0.6,0.7,0.8], 'vect__min_df':[0, 1,2,3],'logi__C':[0.01,0.1,1,10,100], \n",
    "#               'vect__ngram_range':[(1,1),(2,2),(3,3)]}\n",
    "# pipeline = Pipeline(\n",
    "#     [\n",
    "#         (\"vect\", CountVectorizer()),\n",
    "#         ('logi', LogisticRegression(max_iter = 100))\n",
    "#     ]\n",
    "# )\n",
    "# grid = GridSearchCV(pipeline, param_grid)\n",
    "# grid.fit(x_train['1'], y_train.values.reshape(-1))\n",
    "# print(grid.cv_results_)\n",
    "# print(grid.best_params_)\n",
    "# print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7569ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid.fit(x_train['2'], y_train.values.reshape(-1))\n",
    "# print(grid.cv_results_)\n",
    "# print(grid.best_params_)\n",
    "# print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66023ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid.fit(x_train['text_processed'], y_train.values.reshape(-1))\n",
    "# print(grid.cv_results_)\n",
    "# print(grid.best_params_)\n",
    "# print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbf655c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b3f8c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #tfidf\n",
    "# param_grid = {'vect__max_df':[0.7, 0.6, 0.8,0.9], 'vect__min_df':[0, 1,2,3],'logi__C':[0.01,0.1,1,10,100], \n",
    "#               'vect__ngram_range':[(1,1),(2,2),(3,3)]}\n",
    "# pipeline = Pipeline(\n",
    "#     [\n",
    "#         (\"vect\", TfidfVectorizer()),\n",
    "#         ('logi', LogisticRegression(max_iter = 100))\n",
    "#     ]\n",
    "# )\n",
    "# grid = GridSearchCV(pipeline, param_grid)\n",
    "# grid.fit(x_train['1'], y_train.values.reshape(-1))\n",
    "# print(grid.cv_results_)\n",
    "# print(grid.best_params_)\n",
    "# print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ee85f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid.fit(x_train['2'], y_train.values.reshape(-1))\n",
    "# print(grid.cv_results_)\n",
    "# print(grid.best_params_)\n",
    "# print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e93f7ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid.fit(x_train['text_processed'], y_train.values.reshape(-1))\n",
    "# print(grid.cv_results_)\n",
    "# print(grid.best_params_)\n",
    "# print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "748ae0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = grid.cv_results_['rank_test_score'] == 1\n",
    "# np.array(grid.cv_results_['params'])[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "650f80b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # count vectorizor, 'text processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2131db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # countvectorize\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param_grid = {'vect__max_df':[0.6,0.7,0.8], 'vect__min_df':[0, 1,2,3],'logi__C':[0.01,0.1,1,10,100], \n",
    "#               'vect__ngram_range':[(1,1),(2,2),(3,3)]}\n",
    "# pipeline = Pipeline(\n",
    "#     [\n",
    "#         (\"vect\", CountVectorizer()),\n",
    "#         ('logi', LogisticRegression(max_iter = 100))\n",
    "#     ]\n",
    "# )\n",
    "# grid = GridSearchCV(pipeline, param_grid)\n",
    "# grid.fit(x_train['1'], y_train.values.reshape(-1))\n",
    "# print(grid.cv_results_)\n",
    "# print(grid.best_params_)\n",
    "# print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30f96c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a1ff89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "520.85px",
    "left": "1150.2px",
    "right": "20px",
    "top": "121px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
